{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ejercicio 4: Modelo Probabilístico\n",
    "\n",
    "## Objetivo de la práctica\n",
    "- Comprender los componentes del modelo vectorial mediante cálculos manuales y observación directa.\n",
    "- Aplicar el modelo de espacio vectorial con TF-IDF para recuperar documentos relevantes.\n",
    "- Comparar la recuperación con BM25 frente a TF-IDF.\n",
    "- Analizar visualmente las diferencias entre los modelos.\n",
    "- Evaluar si los rankings generados son consistentes con lo que considerarías documentos relevantes."
   ],
   "id": "941741204a003f44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Parte 0: Carga del Corpus",
   "id": "93bafe7a6a4ef9e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:46:29.170287Z",
     "start_time": "2025-11-17T15:46:25.592310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroupsdocs = newsgroups.data"
   ],
   "id": "ad08bb8bd43ae327",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parte 1: Cálculo de TF, DF, IDF y TF-IDF\n",
    "\n",
    "### Actividad \n",
    "1. Utiliza el corpus cargado.\n",
    "2. Construye la matriz de términos (TF), y calcula la frecuencia de documentos (DF)\n",
    "3. Calcula TF-IDF utilizando sklearn.\n",
    "4. Visualiza los valores en un DataFrame para analizar las diferencias entre los términos."
   ],
   "id": "10f8c7f78934f497"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:46:43.992828Z",
     "start_time": "2025-11-17T15:46:43.988047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def clean_text(texto):\n",
    "    texto = re.sub(r'<.*?>', '', texto)\n",
    "    texto = re.sub(r'[.,()\\\"\\'\\x08]', ' ', texto)\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'[^a-z0-9\\s]', ' ', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    return texto"
   ],
   "id": "e08f9d2822da6655",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:47:00.779953Z",
     "start_time": "2025-11-17T15:46:59.214468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(newsgroupsdocs, columns=['doc'])\n",
    "df_clean = df['doc'].apply(clean_text)\n",
    "df_clean"
   ],
   "id": "59578312eb3d9941",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i am sure some bashers of pens fans are pretty...\n",
       "1        my brother is in the market for a high perform...\n",
       "2        finally you said what you dream about mediterr...\n",
       "3        think it s the scsi card doing the dma transfe...\n",
       "4        1 i have an old jasmine drive which i cannot u...\n",
       "                               ...                        \n",
       "18841    dn from nyeda cnsvax uwec edu david nye dn a n...\n",
       "18842    not in isolated ground recepticles usually an ...\n",
       "18843    i just installed a dx2 66 cpu in a clone mothe...\n",
       "18844    wouldn t this require a hyper sphere in 3 spac...\n",
       "18845    after a tip from gary crum crum fcom cc utah e...\n",
       "Name: doc, Length: 18846, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:48:57.862661Z",
     "start_time": "2025-11-17T15:48:57.085686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import porter\n",
    "import re\n",
    "\n",
    "# Descargar recursos una sola vez\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "stemmer = porter.PorterStemmer()\n",
    "\n",
    "def preprocesar(texto):\n",
    "    tokens = word_tokenize(texto)\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in stop]\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return tokens"
   ],
   "id": "2a0e2f27cd76affc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asus12\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus12\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:05:06.033443Z",
     "start_time": "2025-11-17T16:05:06.026128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "def get_vocabulario(docs):\n",
    "    vocab = set()\n",
    "    for doc in docs:\n",
    "        vocab.update(doc)\n",
    "    return sorted(list(vocab))\n",
    "\n",
    "def calcular_tf(doc, vocab):\n",
    "    tf = {}\n",
    "    total = len(doc)\n",
    "    if total == 0:\n",
    "        return {term: 0 for term in vocab}\n",
    "    for term in vocab:\n",
    "        tf[term] = doc.count(term) / total\n",
    "    return tf\n",
    "\n",
    "def calcular_idf(corpus, vocab):\n",
    "    N = len(corpus)\n",
    "    idf = {}\n",
    "    for term in vocab:\n",
    "        df = sum(1 for doc in corpus if term in doc)\n",
    "        idf[term] = math.log(N / (df if df > 0 else 1))\n",
    "    return idf\n",
    "\n",
    "def calcular_tfidf(corpus, vocab, idf):\n",
    "    tfidf_docs = []\n",
    "    for doc in corpus:\n",
    "        tf = calcular_tf(doc, vocab)\n",
    "        tfidf = {term: tf[term] * idf[term] for term in vocab}\n",
    "        tfidf_docs.append(tfidf)\n",
    "    return tfidf_docs"
   ],
   "id": "d6f5aef42963cb4d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:00:43.572818Z",
     "start_time": "2025-11-17T16:00:43.563068Z"
    }
   },
   "cell_type": "code",
   "source": "type(df_clean)\n",
   "id": "cf688291052dfaea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:05:14.536912Z",
     "start_time": "2025-11-17T16:05:14.532507Z"
    }
   },
   "cell_type": "code",
   "source": "df_10 = df_clean.head(1000)",
   "id": "16d70e7866ad10ae",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:12:48.490047Z",
     "start_time": "2025-11-17T16:12:47.151585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lista de listas\n",
    "corpus_preprocesado = [preprocesar(doc) for doc in df_10]"
   ],
   "id": "11565f4bffee1ebe",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TF-IDF manual",
   "id": "b771aea3db22be03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:13:38.787690Z",
     "start_time": "2025-11-17T16:12:52.715005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Vocabulario\n",
    "vocab = get_vocabulario(corpus_preprocesado)\n",
    "# 2. IDF del corpus\n",
    "idf = calcular_idf(corpus_preprocesado, vocab)\n",
    "# 3. TF-IDF final\n",
    "tfidf = calcular_tfidf(corpus_preprocesado, vocab, idf)"
   ],
   "id": "90f024c2a46dc271",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:23:34.966958Z",
     "start_time": "2025-11-17T16:23:29.602851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_tfidf = pd.DataFrame(tfidf)\n",
    "print(df_tfidf)"
   ],
   "id": "6fff3b3b61fa9efb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      aa  aaa  aaahhhh  aacvkc  aamir  aammmaaaazzzzzziinnnnggggg  aap  \\\n",
      "0    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "1    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "2    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "3    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "4    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "..   ...  ...      ...     ...    ...                         ...  ...   \n",
      "995  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "996  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "997  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "998  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "999  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
      "\n",
      "     aardvark   ab  abandon  ...  zooid  zoom  zubkoff  zubov  zuki  zur  \\\n",
      "0         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "1         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "2         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "3         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "4         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "..        ...  ...      ...  ...    ...   ...      ...    ...   ...  ...   \n",
      "995       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "996       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "997       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "998       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "999       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
      "\n",
      "     zurbrin   zv  zviq  zzzzzzt  \n",
      "0        0.0  0.0   0.0      0.0  \n",
      "1        0.0  0.0   0.0      0.0  \n",
      "2        0.0  0.0   0.0      0.0  \n",
      "3        0.0  0.0   0.0      0.0  \n",
      "4        0.0  0.0   0.0      0.0  \n",
      "..       ...  ...   ...      ...  \n",
      "995      0.0  0.0   0.0      0.0  \n",
      "996      0.0  0.0   0.0      0.0  \n",
      "997      0.0  0.0   0.0      0.0  \n",
      "998      0.0  0.0   0.0      0.0  \n",
      "999      0.0  0.0   0.0      0.0  \n",
      "\n",
      "[1000 rows x 11816 columns]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TF-IDF Sklean",
   "id": "e564ff9adb8cbced"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:21:34.963535Z",
     "start_time": "2025-11-17T16:21:34.907396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# trabaja con strings\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x,lowercase=False)\n",
    "tfidf_sklearn = vectorizer.fit_transform(corpus_preprocesado)"
   ],
   "id": "2edc2bd434fb9e5",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:24:32.839262Z",
     "start_time": "2025-11-17T16:24:32.589321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = vectorizer.get_feature_names_out()\n",
    "df_tfidf_sklearn = pd.DataFrame(tfidf_sklearn.toarray(), columns=vocab)\n",
    "df_tfidf_sklearn"
   ],
   "id": "ab10eb03a89545fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      aa  aaa  aaahhhh  aacvkc  aamir  aammmaaaazzzzzziinnnnggggg  aap  \\\n",
       "0    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "1    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "2    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "3    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "4    0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "..   ...  ...      ...     ...    ...                         ...  ...   \n",
       "995  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "996  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "997  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "998  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "999  0.0  0.0      0.0     0.0    0.0                         0.0  0.0   \n",
       "\n",
       "     aardvark   ab  abandon  ...  zooid  zoom  zubkoff  zubov  zuki  zur  \\\n",
       "0         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "1         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "2         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "3         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "4         0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "..        ...  ...      ...  ...    ...   ...      ...    ...   ...  ...   \n",
       "995       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "996       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "997       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "998       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "999       0.0  0.0      0.0  ...    0.0   0.0      0.0    0.0   0.0  0.0   \n",
       "\n",
       "     zurbrin   zv  zviq  zzzzzzt  \n",
       "0        0.0  0.0   0.0      0.0  \n",
       "1        0.0  0.0   0.0      0.0  \n",
       "2        0.0  0.0   0.0      0.0  \n",
       "3        0.0  0.0   0.0      0.0  \n",
       "4        0.0  0.0   0.0      0.0  \n",
       "..       ...  ...   ...      ...  \n",
       "995      0.0  0.0   0.0      0.0  \n",
       "996      0.0  0.0   0.0      0.0  \n",
       "997      0.0  0.0   0.0      0.0  \n",
       "998      0.0  0.0   0.0      0.0  \n",
       "999      0.0  0.0   0.0      0.0  \n",
       "\n",
       "[1000 rows x 11816 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaahhhh</th>\n",
       "      <th>aacvkc</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aammmaaaazzzzzziinnnnggggg</th>\n",
       "      <th>aap</th>\n",
       "      <th>aardvark</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>zooid</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zubkoff</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zuki</th>\n",
       "      <th>zur</th>\n",
       "      <th>zurbrin</th>\n",
       "      <th>zv</th>\n",
       "      <th>zviq</th>\n",
       "      <th>zzzzzzt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11816 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parte 2: Ranking de documentos usando TF-IDF\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Dada una consulta, construye el vector de consulta\n",
    "2. Calcula la similitud coseno entre la consulta y cada documento usando los vectores TF-IDF\n",
    "3. Genera un ranking de los documentos ordenados por relevancia.\n",
    "4. Muestra los resultados en una tabla."
   ],
   "id": "64491bce5361e8b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:34:58.043585Z",
     "start_time": "2025-11-17T16:34:58.030580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def procesar_query(query):\n",
    "    limpio = clean_text(query)\n",
    "    tokens = preprocesar(limpio)\n",
    "    return \" \".join(tokens)"
   ],
   "id": "ad549258f6f7077f",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:36:23.266002Z",
     "start_time": "2025-11-17T16:36:23.244812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def buscar(query, top_k=5):\n",
    "    query_proc = procesar_query(query)\n",
    "    query_vec = vectorizer.transform([query_proc])\n",
    "    # similitud de coseno entre consulta y cada documento\n",
    "    sims = cosine_similarity(query_vec, df_tfidf_sklearn)[0]\n",
    "    # ordenar descendentemente por similitud\n",
    "    ranking = sims.argsort()[::-1][:top_k]\n",
    "    return [(i, sims[i]) for i in ranking]"
   ],
   "id": "9fdd7b9fbe51b044",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:41:09.276550Z",
     "start_time": "2025-11-17T16:41:09.269200Z"
    }
   },
   "cell_type": "code",
   "source": "query = \"vegetable\"",
   "id": "e09b7c681b233d84",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:41:10.167622Z",
     "start_time": "2025-11-17T16:41:10.158495Z"
    }
   },
   "cell_type": "code",
   "source": "procesar_query(query)",
   "id": "e32762711029dd78",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veget'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:41:11.618752Z",
     "start_time": "2025-11-17T16:41:11.449271Z"
    }
   },
   "cell_type": "code",
   "source": "buscar(query,  top_k=5)",
   "id": "25d103895a454f5e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.int64(493), np.float64(0.428766909410498)),\n",
       " (np.int64(458), np.float64(0.23668304217800426)),\n",
       " (np.int64(500), np.float64(0.23519909445816645)),\n",
       " (np.int64(543), np.float64(0.21828567518469058)),\n",
       " (np.int64(531), np.float64(0.21377750944553447))]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T16:41:17.418153Z",
     "start_time": "2025-11-17T16:41:17.406814Z"
    }
   },
   "cell_type": "code",
   "source": "df_10[493]",
   "id": "d5b6abacbb9b9667",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a slightly used less than two months old suprafaxmodem is for sale it comes with latest rom 1 2h communication software fax software original manuals and the original registration card here are some specs model supfaxv32bis description suprafaxmodem v 32bis type internal data speed 14 400 12 000 9600 7200 4800 2400 1200 300 bps data upto 57000bps with v 42 data compression protocols bell 103 212a ccit v 21 v 22 v 22bis v 32 v 32bis v 42 v 42bis mnp 2 5 mnp 10 fax 14 400 12 000 9600 7200 4800 2400 bps send receive fax class 1 2 commnads group iii compatible transmission v 17 v 29 v 27ter other non volatile memory autoanswer autodial tone or pulse extended at commands and result codes includes diagnostics phone jacks subscriptions to free online services 5 year warranty asking 180 neg s h if interested please e mail'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parte 3: Ranking con BM25\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Implementa un sistema de recuperación usando el modelo BM25.\n",
    "2. Usa la misma consulta del ejercicio anterior.\n",
    "3. Calcula el score BM25 para cada documento y genera un ranking.\n",
    "4. Compara manualmente con el ranking de TF-IDF."
   ],
   "id": "97061325508dc5f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2a0dca2bcfa73c5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parte 4: Comparación visual entre TF-IDF y BM25\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Utiliza un gráfico de barras para visualizar los scores obtenidos por cada documento según TF-IDF y BM25.\n",
    "2. Compara los rankings visualmente.\n",
    "3. Identifica: ¿Qué documentos obtienen scores más altos en un modelo que en otro?\n",
    "4. Sugiere: ¿A qué se podría deber esta diferencia?"
   ],
   "id": "2c71b85e77b4b181"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "16ad3d9d16c04d35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parte 5: Evaluación con consulta relevante\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Elige una consulta y define qué documentos del corpus deberían considerarse relevantes.\n",
    "2. Evalúa Precision@3 o MAP para los rankings generados con TF-IDF y BM25.\n",
    "3. Responde: ¿Cuál modelo da mejores resultados respecto a tu criterio de relevancia?"
   ],
   "id": "b97d171655ecfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d5de59378900ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
